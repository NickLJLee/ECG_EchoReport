{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error  # for MAE computation\n",
    "import yaml as yaml\n",
    "import sys\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import wfdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import random\n",
    "import yaml as yaml\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "import utils_builder\n",
    "from zeroshot_val import zeroshot_eval\n",
    "\n",
    "class LVEF_reg_Dataset(Dataset):\n",
    "    def __init__(self, labels_df, transform=None):\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.ecg_path = '/hot_data/lijun/data/mimic-iv-ecg-diagnostic-electrocardiogram-matched-subset-1.0/'\n",
    "        self.input_leads = ['I', 'II', 'III', 'aVR', 'aVF', 'aVL', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "        self.new_leads = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "        self.lead_indices = [self.input_leads.index(lead) for lead in self.new_leads]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def z_score_normalization(self, signal):\n",
    "        return (signal - np.mean(signal)) / (np.std(signal) + 1e-8) \n",
    "\n",
    "    def check_nan_in_array(self, arr):\n",
    "        contains_nan = np.isnan(arr).any()\n",
    "        return contains_nan\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        hash_file_name = str(self.labels_df.iloc[idx, 5])\n",
    "        labels = self.labels_df.iloc[idx, 3]  # LVEF ground truth label\n",
    "        labels = torch.tensor([labels], dtype=torch.float32)  # Wrap the label in a list to create an extra dimension\n",
    "        data = [wfdb.rdsamp(self.ecg_path + hash_file_name)]\n",
    "        data = np.array([signal for signal, meta in data])\n",
    "        data = np.nan_to_num(data, nan=0)\n",
    "        data = data.squeeze(0)\n",
    "        data = np.transpose(data, (1, 0))\n",
    "        data = data[self.lead_indices, :]\n",
    "        signal = self.z_score_normalization(data)\n",
    "        signal = torch.FloatTensor(signal)\n",
    "\n",
    "        return signal, labels\n",
    "\n",
    "def compute_regression_metric(\n",
    "    ecg_embeddings: torch.Tensor,\n",
    "    prompt_embeddings: torch.Tensor,\n",
    "    prompt_values: torch.Tensor,\n",
    "):\n",
    "    per_frame_similarities = (\n",
    "        ecg_embeddings @ prompt_embeddings\n",
    "    )\n",
    "\n",
    "    ranked_candidate_phrase_indices = torch.argsort(\n",
    "        per_frame_similarities, dim=-1, descending=True\n",
    "    )\n",
    "\n",
    "    prompt_values = torch.tensor(\n",
    "        prompt_values, device=ecg_embeddings.device\n",
    "    )\n",
    "\n",
    "    all_frames_ranked_values = prompt_values[ranked_candidate_phrase_indices]\n",
    "    avg_frame_ranked_values = all_frames_ranked_values.float().mean(dim=0)\n",
    "    # print(prompt_embeddings.shape)\n",
    "    # print(\"all:\",all_frames_ranked_values)\n",
    "    # print(\"avg:\",avg_frame_ranked_values)\n",
    "    twenty_percent = int(avg_frame_ranked_values.shape[0] * 0.8)\n",
    "    top_twenty_percent_values = avg_frame_ranked_values[:twenty_percent]\n",
    "    final_prediction = top_twenty_percent_values.median()\n",
    "\n",
    "    return final_prediction\n",
    "\n",
    "def lvef_reg(model, loader, device='cuda'):\n",
    "    zero_shot_prompts = {\n",
    "        \"ejection_fraction\": [\n",
    "            \"LVEF = <#>% \",\n",
    "            # \"LVEF > <#>% \",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    ejection_fraction_prompts = zero_shot_prompts[\"ejection_fraction\"]\n",
    "\n",
    "    prompts = []\n",
    "    prompt_values = []\n",
    "    prompt_embeddings = []\n",
    "    model.eval()\n",
    "    for prompt in ejection_fraction_prompts:\n",
    "        for i in range(101):\n",
    "            prompts.append(prompt.replace(\"<#>\", str(i)))\n",
    "            prompt_values.append(i)\n",
    "\n",
    "    for prompt in tqdm(prompts):\n",
    "        prompt = [prompt]\n",
    "        ejection_fraction_prompts = model.module._tokenize(prompt)\n",
    "        class_embeddings = model.module.get_text_emb(\n",
    "            ejection_fraction_prompts.input_ids.to(device=device),\n",
    "            ejection_fraction_prompts.attention_mask.to(device=device)\n",
    "        )\n",
    "        class_embeddings = model.module.proj_t(class_embeddings)\n",
    "        class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
    "        class_embedding = class_embeddings.mean(dim=0)\n",
    "        class_embedding /= class_embedding.norm()\n",
    "        prompt_embeddings.append(class_embedding)\n",
    "\n",
    "    ecg_embeddings = []\n",
    "    ejection_fraction_predictions = []\n",
    "    ground_truths = []  # Store ground truth values\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (ecg, target) in enumerate(tqdm(loader)):\n",
    "            ecg = ecg.to(device=device)\n",
    "            ecg_emb = model.module.ext_ecg_emb(ecg)\n",
    "            ecg_emb /= ecg_emb.norm(dim=-1, keepdim=True)\n",
    "            ecg_embeddings.append(ecg_emb)\n",
    "            ground_truths.extend(target.numpy())  # Collect ground truth labels\n",
    "\n",
    "    ecg_embeddings = torch.cat(ecg_embeddings, dim=0)\n",
    "    prompt_embeddings = torch.stack(prompt_embeddings, dim=1)\n",
    "\n",
    "    for i in range(ecg_embeddings.shape[0]):\n",
    "        ejection_fraction_prediction = compute_regression_metric(\n",
    "            ecg_embeddings[i,:].unsqueeze(0), prompt_embeddings, torch.tensor(prompt_values).to(device=device)\n",
    "        )\n",
    "        ejection_fraction_predictions.append(ejection_fraction_prediction)\n",
    "\n",
    "    return ejection_fraction_predictions, ground_truths\n",
    "\n",
    "\n",
    "# Main execution block\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "device_id = 'cuda:0'\n",
    "\n",
    "config = yaml.load(open(\"zeroshot_config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "\n",
    "model = utils_builder.ECGCLIP(config['network'])\n",
    "ckpt = '/data1/1shared/lijun/ecg/ECG-EchoReport/checkpoints/I313_I314_zero-shot_10_ckpt.pth'\n",
    "ckpt = torch.load(f'{ckpt}', map_location='cpu')\n",
    "model.load_state_dict(ckpt)\n",
    "model = model.to(device_id)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "df_label = '/home/lijun/code/LVEF.csv'\n",
    "df_label = pd.read_csv(df_label)\n",
    "train_df, test_df = train_test_split(df_label, test_size=0.2, shuffle=False)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, shuffle=False)\n",
    "\n",
    "test_dataset = LVEF_reg_Dataset(labels_df=test_df)\n",
    "testloader = DataLoader(test_dataset, batch_size=256, num_workers=40, shuffle=False)\n",
    "\n",
    "ejection_fraction_predictions, ground_truths = lvef_reg(model=model, loader=testloader)\n",
    "\n",
    "# Compute Mean Absolute Error (MAE)\n",
    "ground_truths = np.array(ground_truths)\n",
    "# Convert predictions to numpy arrays and ensure they are 1D arrays before concatenation\n",
    "# Ensure each prediction is wrapped into a 1D array before appending to the list\n",
    "ejection_fraction_predictions = [np.expand_dims(pred.cpu().numpy(), axis=0) if isinstance(pred, torch.Tensor) else np.expand_dims(np.array(pred), axis=0) for pred in ejection_fraction_predictions]\n",
    "\n",
    "# Now concatenate the list of NumPy arrays into a single array\n",
    "ejection_fraction_predictions = np.concatenate(ejection_fraction_predictions, axis=0)\n",
    "\n",
    "# Convert ground_truths to NumPy if it's not already\n",
    "ground_truths = np.array(ground_truths)\n",
    "\n",
    "# Create a DataFrame for saving to CSV\n",
    "df = pd.DataFrame({\n",
    "    'Ground_Truth_LVEF': ground_truths.flatten(),  # Flatten to ensure it's 1D\n",
    "    'Predicted_LVEF': ejection_fraction_predictions.flatten()  # Flatten if needed\n",
    "})\n",
    "output_file = '/data1/1shared/lijun/ecg/ECG-EchoReport/res/LVEF_output.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Compute Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(ground_truths, ejection_fraction_predictions)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Extracting the data\n",
    "ground_truth = ground_truths\n",
    "predicted = ejection_fraction_predictions\n",
    "\n",
    "# Calculating Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(ground_truth, predicted)\n",
    "\n",
    "# Fitting a linear regression model\n",
    "# reg_model = LinearRegression()\n",
    "# reg_model.fit(ground_truth, predicted)\n",
    "# predicted_line = reg_model.predict(ground_truth)\n",
    "\n",
    "# Plotting the scatter plot and regression line\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(ground_truth, predicted, alpha=0.5, s=3, color='tab:blue')\n",
    "# plt.scatter(ground_truth, predicted, label='Predicted vs. Ground Truth', color='blue', alpha=0.6)\n",
    "# plt.plot(ground_truth, predicted_line, color='red', label=f'Regression Line\\nMAE: {mae:.2f}')\n",
    "plt.xlim(0, 100)\n",
    "plt.ylim(0, 100)\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Ground Truth LVEF')\n",
    "plt.ylabel('Predicted LVEF')\n",
    "plt.title('Scatter Plot with Regression Line and MAE')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
